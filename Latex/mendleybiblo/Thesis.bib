Automatically generated by Mendeley Desktop 1.11
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{Lin2013,
author = {Lin, Dahua and Fidler, Sanja and Urtasun, Raquel},
doi = {10.1109/ICCV.2013.179},
file = {:C$\backslash$:/Users/liam/Desktop/KINECT/kbox/Latex/papers/Holistic Scene Understanding for 3D Object Detection with RGBD cameras.pdf:pdf},
isbn = {978-1-4799-2840-8},
journal = {2013 IEEE Int. Conf. Comput. Vis.},
month = dec,
pages = {1417--1424},
publisher = {Ieee},
title = {{Holistic Scene Understanding for 3D Object Detection with RGBD Cameras}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6751286},
year = {2013}
}
@article{Palacios2013,
abstract = {In this paper we present a new method for hand gesture recognition based on an RGB-D sensor. The proposed approach takes advantage of depth information to cope with the most common problems of traditional video-based hand segmentation methods: cluttered backgrounds and occlusions. The algorithm also uses colour and semantic information to accurately identify any number of hands present in the image. Ten different static hand gestures are recognised, including all different combinations of spread fingers. Additionally, movements of an open hand are followed and 6 dynamic gestures are identified. The main advantage of our approach is the freedom of the user's hands to be at any position of the image without the need of wearing any specific clothing or additional devices. Besides, the whole method can be executed without any initial training or calibration. Experiments carried out with different users and in different environments prove the accuracy and robustness of the method which, additionally, can be run in real-time.},
author = {Palacios, Jos\'{e} Manuel and Sag\"{u}\'{e}s, Carlos and Montijano, Eduardo and Llorente, Sergio},
doi = {10.3390/s130911842},
file = {:C$\backslash$:/Users/liam/Desktop/KINECT/kbox/Latex/papers/Human-Computer Interaction Based on Hand Gestures Using.pdf:pdf},
issn = {1424-8220},
journal = {Sensors (Basel).},
keywords = {Algorithms,Colorimetry,Colorimetry: instrumentation,Colorimetry: methods,Equipment Design,Equipment Failure Analysis,Gestures,Hand,Hand: anatomy \& histology,Hand: physiology,Humans,Pattern Recognition, Automated,Pattern Recognition, Automated: methods,Reproducibility of Results,Sensitivity and Specificity,Transducers,User-Computer Interface},
month = jan,
number = {9},
pages = {11842--60},
pmid = {24018953},
title = {{Human-computer interaction based on hand gestures using RGB-D sensors.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3821294\&tool=pmcentrez\&rendertype=abstract},
volume = {13},
year = {2013}
}
@article{Rector2013,
author = {Rector, Kyle and Bennett, Cynthia L and Kientz, Julie A},
file = {:C$\backslash$:/Users/liam/Desktop/attachments/kinect\_yoga\_paper.pdf:pdf},
journal = {Int. ACM SIGACCESS Conf.},
keywords = {accessibility,audio feedback,exergames,eyes-free,health,ki-,nect,video games,visual impairments,yoga},
title = {{Eyes-Free Yoga : An Exergame Using Depth Cameras for Blind \& Low Vision Exercise}},
year = {2013}
}
@article{Obdrzalek2012,
abstract = {The Microsoft Kinect camera is becoming increasingly popular in many areas aside from entertainment, including human activity monitoring and rehabilitation. Many people, however, fail to consider the reliability and accuracy of the Kinect human pose estimation when they depend on it as a measuring system. In this paper we compare the Kinect pose estimation (skeletonization) with more established techniques for pose estimation from motion capture data, examining the accuracy of joint localization and robustness of pose estimation with respect to the orientation and occlusions. We have evaluated six physical exercises aimed at coaching of elderly population. Experimental results present pose estimation accuracy rates and corresponding error bounds for the Kinect system.},
author = {Obdrz\'{a}lek, Step\'{a}n and Kurillo, Gregorij and Ofli, Ferda and Bajcsy, Ruzena and Seto, Edmund and Jimison, Holly and Pavel, Michael},
doi = {10.1109/EMBC.2012.6346149},
file = {:C$\backslash$:/Users/liam/Desktop/KINECT/kbox/Latex/papers/obdrzalek12embcAccuracyAndRobustnessOfKinectPoseEstimation.pdf:pdf},
issn = {1557-170X},
journal = {Conf. Proc. IEEE Eng. Med. Biol. Soc.},
keywords = {Aged,Aged, 80 and over,Exercise,Female,Humans,Male,Posture,Video Recording},
month = jan,
pages = {1188--93},
pmid = {23366110},
title = {{Accuracy and robustness of Kinect pose estimation in the context of coaching of elderly population.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/23366110},
volume = {2012},
year = {2012}
}
@article{Roweis2000,
abstract = {Many areas of science depend on exploratory data analysis and visualization. The need to analyze large amounts of multivariate data raises the fundamental problem of dimensionality reduction: how to discover compact representations of high-dimensional data. Here, we introduce locally linear embedding (LLE), an unsupervised learning algorithm that computes low-dimensional, neighborhood-preserving embeddings of high-dimensional inputs. Unlike clustering methods for local dimensionality reduction, LLE maps its inputs into a single global coordinate system of lower dimensionality, and its optimizations do not involve local minima. By exploiting the local symmetries of linear reconstructions, LLE is able to learn the global structure of nonlinear manifolds, such as those generated by images of faces or documents of text.},
author = {Roweis, S T and Saul, L K},
doi = {10.1126/science.290.5500.2323},
file = {:C$\backslash$:/Users/liam/Desktop/KINECT/kbox/Latex/mendleybiblo/LLE.pdf:pdf},
issn = {0036-8075},
journal = {Science},
keywords = {Algorithms,Artificial Intelligence,Face,Humans,Mathematics,Pattern Recognition, Visual},
month = dec,
number = {5500},
pages = {2323--6},
pmid = {11125150},
title = {{Nonlinear dimensionality reduction by locally linear embedding.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/11125150},
volume = {290},
year = {2000}
}
@article{Belkin2003,
author = {Belkin, M and Niyogi, P},
file = {:C$\backslash$:/Users/liam/Desktop/KINECT/kbox/Thesis/LaplacianEigenmaps.pdf:pdf},
journal = {Neural Comput.},
title = {{Laplacian eigenmaps for dimensionality reduction and data representation}},
url = {http://www.mitpressjournals.org/doi/abs/10.1162/089976603321780317},
year = {2003}
}
@book{Jana,
author = {Jana, Abhijit},
file = {:C$\backslash$:/Users/liam/Desktop/KINECT/kbox/Thesis/Kinect.for.Windows.SDK.Programming.Guide.pdf:pdf},
isbn = {9781849692380},
title = {{Kinect for Windows SDK Programming Guide}}
}
@article{DelaTorre2012,
author = {{De la Torre}, F.},
doi = {10.1109/CVPR.2012.6247812},
file = {:C$\backslash$:/Users/liam/Desktop/KINECT/kbox/Latex/papers/Generalized Time Warping for multi-modal alignment of human motion.pdf:pdf},
isbn = {978-1-4673-1228-8},
journal = {2012 IEEE Conf. Comput. Vis. Pattern Recognit.},
month = jun,
pages = {1282--1289},
publisher = {Ieee},
title = {{Generalized time warping for multi-modal alignment of human motion}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6247812},
year = {2012}
}
@article{Kinect2012,
author = {Chang, CY and Lange, B and Zhang, M},
file = {:C$\backslash$:/Users/liam/Desktop/KINECT/kbox/Latex/papers/Motion Comparison using xbox kinect.pdf:pdf},
journal = {Pervasive \ldots},
title = {{Towards pervasive physical rehabilitation using Microsoft Kinect}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=6240377},
year = {2012}
}
@article{Celiktutan2013a,
author = {\c{C}eliktutan, Oya and Akg\"{u}l, Ceyhun Burak and Wolf, Christian and Sankur, B\"{u}lent},
file = {:C$\backslash$:/Users/liam/Desktop/KINECT/kbox/Latex/papers/Graph-Based Analysis of Physical Exercise Actions.pdf:pdf},
isbn = {9781450323987},
keywords = {action quality assess-,action recognition,hyper-graph matching,ment,sequence alignment},
title = {{Graph-Based Analysis of Physical Exercise Actions}},
year = {2013}
}
@article{Yang2014,
author = {Yang, Xiaodong and Tian, YingLi},
doi = {10.1016/j.jvcir.2013.03.001},
file = {:C$\backslash$:/Users/liam/Desktop/KINECT/kbox/Latex/papers/Effective 3D Action Recognition Using EigenJoints.pdf:pdf},
issn = {10473203},
journal = {J. Vis. Commun. Image Represent.},
keywords = {3d action feature representation,action recognition,depth data,rgbd camera,skeleton joints},
month = jan,
number = {1},
pages = {2--11},
title = {{Effective 3D action recognition using EigenJoints}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1047320313000333},
volume = {25},
year = {2014}
}
@article{Xia2012,
author = {Xia, Lu and Chen, Chia-chih and Aggarwal, JK},
file = {:C$\backslash$:/Users/liam/Desktop/KINECT/kbox/Latex/papers/View Invariant Human Action Recognition Using Histograms of 3D Joints.pdf:pdf},
journal = {CVPR 2012 HAU3D Work.},
title = {{View invariant human action recognition using histograms of 3D joints The University of Texas at Austin}},
url = {http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:View+Invariant+Human+Action+Recognition+Using+Histograms+of+3D+Joints+The+University+of+Texas+at+Austin\#1},
year = {2012}
}
@article{Demartines1997,
abstract = {We present a new strategy called "curvilinear component analysis" (CCA) for dimensionality reduction and representation of multidimensional data sets. The principle of CCA is a self-organized neural network performing two tasks: vector quantization (VQ) of the submanifold in the data set (input space); and nonlinear projection (P) of these quantizing vectors toward an output space, providing a revealing unfolding of the submanifold. After learning, the network has the ability to continuously map any new point from one space into another: forward mapping of new points in the input space, or backward mapping of an arbitrary position in the output space.},
author = {Demartines, P and Herault, J},
doi = {10.1109/72.554199},
file = {:C$\backslash$:/Users/liam/Downloads/download.pdf:pdf},
issn = {1045-9227},
journal = {IEEE Trans. Neural Netw.},
month = jan,
number = {1},
pages = {148--54},
pmid = {18255618},
title = {{Curvilinear component analysis: a self-organizing neural network for nonlinear mapping of data sets.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18255618},
volume = {8},
year = {1997}
}
@article{Miranda2014,
author = {Miranda, Leandro and Vieira, Thales and Mart\'{\i}nez, Dimas and Lewiner, Thomas and Vieira, Antonio W. and {M. Campos}, Mario F.},
doi = {10.1016/j.patrec.2013.10.005},
file = {:C$\backslash$:/Users/liam/Desktop/KINECT/kbox/Latex/papers/Online gesture recognition from pose kernel learning.pdf:pdf},
issn = {01678655},
journal = {Pattern Recognit. Lett.},
keywords = {key pose identification,online gesture recognition,skeleton representation},
month = apr,
pages = {65--73},
publisher = {Elsevier B.V.},
title = {{Online gesture recognition from pose kernel learning and decision forests}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0167865513003784},
volume = {39},
year = {2014}
}
@book{Ke2013,
author = {Ke, Shian-Ru and Thuc, Hoang and Lee, Yong-Jin and Hwang, Jenq-Neng and Yoo, Jang-Hee and Choi, Kyoung-Ho},
booktitle = {Computers},
doi = {10.3390/computers2020088},
file = {:C$\backslash$:/Users/liam/Desktop/KINECT/kbox/Latex/papers/A Review on Video-Based Human Activity Recognition.pdf:pdf},
isbn = {1206708344},
issn = {2073-431X},
keywords = {feature representation,healthcare monitoring,human activity recognition,human computer interface,security surveillance,segmentation},
month = jun,
number = {2},
pages = {88--131},
title = {{A Review on Video-Based Human Activity Recognition}},
url = {http://www.mdpi.com/2073-431X/2/2/88/},
volume = {2},
year = {2013}
}
@article{Koppula2013,
author = {Koppula, H. S. and Gupta, R. and Saxena, a.},
doi = {10.1177/0278364913478446},
file = {:C$\backslash$:/Users/liam/Desktop/KINECT/kbox/Latex/papers/The International Journal of Robotics Research-2013.pdf:pdf},
issn = {0278-3649},
journal = {Int. J. Rob. Res.},
keywords = {3d perception,human activity detection,object affordance,personal robots,spatio-temporal context,supervised learning},
month = jul,
number = {8},
pages = {951--970},
title = {{Learning human activities and object affordances from RGB-D videos}},
url = {http://ijr.sagepub.com/cgi/doi/10.1177/0278364913478446},
volume = {32},
year = {2013}
}
@article{Raptis2011a,
address = {New York, New York, USA},
author = {Raptis, Michalis and Kirovski, Darko and Hoppe, Hugues},
doi = {10.1145/2019406.2019426},
file = {:C$\backslash$:/Users/liam/Desktop/KINECT/kbox/Latex/papers/Real-Time Classification of Dance Gestures.pdf:pdf},
isbn = {9781450309233},
journal = {Proc. 2011 ACM SIGGRAPH/Eurographics Symp. Comput. Animat. - SCA '11},
pages = {147},
publisher = {ACM Press},
title = {{Real-time classification of dance gestures from skeleton animation}},
url = {http://dl.acm.org/citation.cfm?doid=2019406.2019426},
year = {2011}
}
@article{Yamaoka2013,
author = {Yamaoka, Koji and Uehara, Masataka and Shima, Takeshi and Tamura, Yasuhisa},
doi = {10.1016/j.procs.2013.09.174},
file = {:C$\backslash$:/Users/liam/Desktop/attachments/resource [2].pdf:pdf},
issn = {18770509},
journal = {Procedia Comput. Sci.},
keywords = {capture,feedback,flying disc,kinect,throwing movement},
month = jan,
pages = {912--920},
publisher = {Elsevier Masson SAS},
title = {{Feedback of Flying Disc Throw with Kinect and its Evaluation}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1877050913009678},
volume = {22},
year = {2013}
}
@article{Coifman2006,
author = {Coifman, Ronald R. and Lafon, St\'{e}phane},
doi = {10.1016/j.acha.2006.04.006},
file = {:C$\backslash$:/Users/liam/Desktop/KINECT/kbox/Thesis/diffmaps.pdf:pdf},
issn = {10635203},
journal = {Appl. Comput. Harmon. Anal.},
keywords = {diffusion metric,diffusion processes,dimensionality reduction,eigenmaps,graph laplacian,manifold learning},
month = jul,
number = {1},
pages = {5--30},
title = {{Diffusion maps}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1063520306000546},
volume = {21},
year = {2006}
}
@article{Sanna2012,
author = {Sanna, Andrea and Lamberti, Fabrizio and Paravati, Gianluca and Rocha, Felipe Domingues},
doi = {10.1007/s12193-012-0113-9},
file = {:C$\backslash$:/Users/liam/Desktop/KINECT/kbox/Latex/papers/A kinect-based interface to animate virtual characters.pdf:pdf},
issn = {1783-7677},
journal = {J. Multimodal User Interfaces},
keywords = {animation,kinect-based interfaces,natural interfaces,virtual character},
month = oct,
number = {4},
pages = {269--279},
title = {{A kinect-based interface to animate virtual characters}},
url = {http://link.springer.com/10.1007/s12193-012-0113-9},
volume = {7},
year = {2012}
}
@article{Alexiadis2011,
address = {New York, New York, USA},
author = {Alexiadis, Dimitrios S. and Kelly, Philip and Daras, Petros and O'Connor, Noel E. and Boubekeur, Tamy and Moussa, Maher Ben},
doi = {10.1145/2072298.2072412},
file = {:C$\backslash$:/Users/liam/Desktop/attachments/2.Dancer Performance.pdf:pdf},
isbn = {9781450306164},
journal = {Proc. 19th ACM Int. Conf. Multimed. - MM '11},
keywords = {microsoft kinect,signal processing,skeleton tracking},
pages = {659},
publisher = {ACM Press},
title = {{Evaluating a dancer's performance using kinect-based skeleton tracking}},
url = {http://dl.acm.org/citation.cfm?doid=2072298.2072412},
year = {2011}
}
@article{Trindade2012,
author = {Trindade, Pedro and Lobo, Jorge and Barreto, Joao P.},
doi = {10.1109/MFI.2012.6343032},
file = {:C$\backslash$:/Users/liam/Desktop/KINECT/kbox/Latex/papers/Hand gesture recognition using color and depth images.pdf:pdf},
isbn = {978-1-4673-2512-7},
journal = {2012 IEEE Int. Conf. Multisens. Fusion Integr. Intell. Syst.},
month = sep,
pages = {71--76},
publisher = {Ieee},
title = {{Hand gesture recognition using color and depth images enhanced with hand angular pose data}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6343032},
year = {2012}
}
@incollection{Zhang2003,
author = {Zhang, Zhenyue and Zha, Hongyuan},
booktitle = {Intell. Data Eng. Autom. Learn.},
file = {:C$\backslash$:/Users/liam/Desktop/KINECT/kbox/Latex/mendleybiblo/LTSA.pdf:pdf},
pages = {477--481},
title = {{Nonlinear Dimension Reduction via Local}},
year = {2003}
}
@article{Shotton2011,
author = {Shotton, Jamie and Fitzgibbon, Andrew and Cook, Mat and Sharp, Toby and Finocchio, Mark and Moore, Richard and Kipman, Alex and Blake, Andrew},
doi = {10.1109/CVPR.2011.5995316},
file = {:C$\backslash$:/Users/liam/Desktop/KINECT/kbox/Thesis/MsResearch/BodyPartRecognition.pdf:pdf},
isbn = {978-1-4577-0394-2},
journal = {Cvpr 2011},
month = jun,
pages = {1297--1304},
publisher = {Ieee},
title = {{Real-time human pose recognition in parts from single depth images}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5995316},
year = {2011}
}
@article{Moore2012,
abstract = {Quiet eye training expedites skill learning and facilitates anxiety-resistant performance. Changes in response programming and external focus of attention may explain such benefits. We examined the effects of quiet eye training on golf-putting performance, quiet eye duration, kinematics (clubhead acceleration), and physiological (heart rate, muscle activity) responses. Forty participants were assigned to a quiet eye or technical trained group and completed 420 baseline, training, retention, and pressure putts. The quiet eye group performed more accurately and displayed more effective gaze control, lower clubhead acceleration, greater heart rate deceleration, and reduced muscle activity than the technical trained group during retention and pressure tests. Thus, quiet eye training was linked to indirect measures of improved response programming and an external focus. Mediation analyses partially endorsed a response programming explanation.},
author = {Moore, Lee J and Vine, Samuel J and Cooke, Andrew and Ring, Christopher and Wilson, Mark R},
doi = {10.1111/j.1469-8986.2012.01379.x},
file = {:C$\backslash$:/Users/liam/Desktop/KINECT/kbox/Thesis/QuietEye.pdf:pdf},
issn = {1540-5958},
journal = {Psychophysiology},
keywords = {Adolescent,Anxiety,Anxiety: physiopathology,Attention,Attention: physiology,Biomechanical Phenomena,Biomechanical Phenomena: physiology,Eye Movements,Eye Movements: physiology,Female,Golf,Heart Rate,Heart Rate: physiology,Humans,Learning,Learning: physiology,Male,Psychomotor Performance,Psychomotor Performance: physiology,Visual Perception,Visual Perception: physiology,Young Adult},
month = jul,
number = {7},
pages = {1005--15},
pmid = {22564009},
title = {{Quiet eye training expedites motor learning and aids performance under heightened anxiety: the roles of response programming and external attention.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/22564009},
volume = {49},
year = {2012}
}
@article{Lei2012,
address = {New York, New York, USA},
author = {Lei, Jinna and Ren, Xiaofeng and Fox, Dieter},
doi = {10.1145/2370216.2370248},
file = {:C$\backslash$:/Users/liam/Desktop/KINECT/kbox/Latex/papers/Fine-Grained Kitchen Activity Recognition using RGB-D.pdf:pdf},
isbn = {9781450312240},
journal = {Proc. 2012 ACM Conf. Ubiquitous Comput. - UbiComp '12},
pages = {208},
publisher = {ACM Press},
title = {{Fine-grained kitchen activity recognition using RGB-D}},
url = {http://dl.acm.org/citation.cfm?doid=2370216.2370248},
year = {2012}
}
@article{Chen2013,
author = {Chen, Yen-Lin and Wu, Hsiang-Tao and Shi, Fuhao and Tong, Xin and Chai, Jinxiang},
doi = {10.1109/ICCV.2013.449},
file = {:C$\backslash$:/Users/liam/Desktop/KINECT/kbox/Latex/papers/Accurate and Robust 3D Facial Capture Using a Single RGBD Camera.pdf:pdf},
isbn = {978-1-4799-2840-8},
journal = {2013 IEEE Int. Conf. Comput. Vis.},
month = dec,
pages = {3615--3622},
publisher = {Ieee},
title = {{Accurate and Robust 3D Facial Capture Using a Single RGBD Camera}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6751561},
year = {2013}
}
